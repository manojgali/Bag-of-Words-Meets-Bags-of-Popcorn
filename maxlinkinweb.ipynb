{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPl6Dp99vmbElaWbz5PaQQJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manojgali/Bag-of-Words-Meets-Bags-of-Popcorn/blob/master/maxlinkinweb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQxlqul07VXG"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import nltk\n",
        "import html\n",
        "from nltk.corpus import stopwords\n",
        "import math"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfN2mKGa8V27"
      },
      "source": [
        "def wwwcheck(s):\n",
        "    if \"www\" in s:\n",
        "        return s\n",
        "    else:\n",
        "        return \"www.\"+s"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9hPBOHetrn1"
      },
      "source": [
        "H = {}\n",
        "\n",
        "\n",
        "\n",
        "depth = 0\n",
        "\n",
        "urls = {}\n",
        "sort={}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxNXo6Dn-yz5"
      },
      "source": [
        "def crawl(u):\n",
        "    r  = requests.get(u, \"lxml\")\n",
        "    data = r.text\n",
        "    soup = BeautifulSoup(data, \"html.parser\")\n",
        "    return soup"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaxH1Hy1-7q0"
      },
      "source": [
        "def crawler(url,terminator=10):\n",
        "    global urls\n",
        "    global depth\n",
        "    global sort\n",
        "    global freqmatrix\n",
        "\n",
        "    if depth < terminator:\n",
        "        depth = depth+1\n",
        "        crawlresult = crawl(url)\n",
        "       \n",
        "        links = crawlresult.find_all('a')\n",
        "\n",
        "        urls[url]['out'] = len(links)\n",
        "\n",
        "        #print(url + '\\t is crawled')\n",
        "\n",
        "        for link in links:\n",
        "            tag = link.get('href')\n",
        "            href_tag = str(tag)\n",
        "            if href_tag[-1:] == '/':\n",
        "                pass\n",
        "            else:\n",
        "                href_tag = href_tag + '/'\n",
        "            if \"http\" in href_tag:\n",
        "                if href_tag in urls.keys():\n",
        "                    if 'in' in urls[href_tag].keys():\n",
        "                        urls[href_tag]['in'] = urls[href_tag]['in']+1\n",
        "                    elif 'out' in urls[href_tag].keys():\n",
        "                        urls[href_tag]['in'] = 1\n",
        "                    else:\n",
        "                        urls[href_tag] = {}\n",
        "                        urls[href_tag]['in'] = 1\n",
        "                        crawler(href_tag)\n",
        "                else:\n",
        "                    urls[href_tag] = {}\n",
        "                    urls[href_tag]['in'] = 1\n",
        "                    crawler(href_tag)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JHNODPnBmmy"
      },
      "source": [
        "start = 'http://www.google.co.in/'\n",
        "urls[start] = {}\n",
        "\n",
        "urls[start]['in'] = 1\n",
        "\n",
        "\n",
        "crawler(start, terminator  = 5)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Joa1xp-kBuae"
      },
      "source": [
        "for url in urls.keys():\n",
        "    if 'out' not in urls[url].keys():\n",
        "        urls[url]['ratio'] = -1\n",
        "    elif urls[url]['out'] == 0:\n",
        "        urls[url]['ratio'] = -1\n",
        "    else:\n",
        "        urls[url]['ratio']= urls[url]['in']/urls[url]['out']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WGDMuIPLsNY"
      },
      "source": [
        "def findMax( left, right,max):\n",
        "\t\n",
        "\tif left == right:\n",
        "\t\t   \n",
        "\t\tif (max[1]['ratio'] < data[left][1]['ratio']):\t  \n",
        "\t\t\tmax = data[left]\n",
        "\n",
        "\t\treturn  max\n",
        "\n",
        "\n",
        "\tif (right - left == 1) :\t   \n",
        "\n",
        "\t\tif (data[left][1]['ratio'] < data[right][1]['ratio']): \n",
        "\t\t\n",
        "\t\t\tif (max[1]['ratio'] < data[right][1]['ratio']):  \n",
        "\t\t\t\tmax = data[right]\n",
        "\n",
        "\t\telse:\n",
        "\t\t\t\n",
        "\t\t\tif (max[1]['ratio'] < data[left][1]['ratio']):   \n",
        "\t\t\t\tmax = data[left]\n",
        "\n",
        "\t\treturn  max\n",
        "\n",
        "\t# find mid element\n",
        "\tmid = (left + right) // 2\n",
        "\n",
        "\t# recur for left sublist\n",
        "\tmax = findMax( left, mid,max)\n",
        "\n",
        "\t# recur for right sublist\n",
        "\tmax = findMax( mid + 1, right,max)\n",
        "\n",
        "\treturn  max"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb6oXly5kXSd"
      },
      "source": [
        "import numpy as np\n",
        "global data\n",
        "data=np.array(list(urls.items()))\n",
        "data.shape[0]\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3heCFJyl0f2",
        "outputId": "ef3ccc5f-8985-4e65-a2ff-99c869beac51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x=findMax(0, data.shape[0]-1,data[0])\n",
        "x"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['https://maps.google.com/maps?hl=en&tab=il/',\n",
              "       {'in': 1, 'out': 1, 'ratio': 1.0}], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    }
  ]
}